// Doxygen page for Phase 5
/*!

\page phase5 Phase 5: Learning to play Tetris

\section sec_phase5 Phase 5: Learning to play Tetris

If you have made it this far: congratulations!

In this phase, you will apply your agents to the game of Tetris:\n<a href="http://en.wikipedia.org/wiki/Tetris">http://en.wikipedia.org/wiki/Tetris</a>.

\subsection sec_code5 Implementation in C: New Tetris environments

The code for 3 tetris environments of increasing complexity is provided to you, and can be downloaded from the project website. Unpack the tgz archive with: <tt>tar xzvf phase5_tetris.tgz</tt>. This includes some .c files, which implement the environment interface specified in environment.h. You can test your agents in the Tetris environments by compiling just as you have done with the grid1D and grid2D environments.
Because your  reinforcement learning agents adhere to the agent-environment interface defined in agent.h, it is applicable to Tetris just as well as to the grid worlds. This is the beauty of modular programming!

\subsection sec_rl5 Reinforcement Learning: Compact states, eligibility traces and beyond!

However, to solve the more complex versions of Tetris with reinforcement learning within reasonable computation time, you will need to delve more deeply into some reinforcement learning concepts, such as compact state representations, eligibility traces, and others. Please ask the supervisor to assist you in this last phase.

\subsection sec_questions5 Questions Phase 5

\li Q5.1 Which Tetris variants were you able to solve?

\li Q5.2 Which extensions, if any, have you made to your reinforcement learning agents to speed up learning for the Tetris environments?

You are now done with the project!

*/
